version: "3.9"

services:
  # Main Django Application
  app:
    build:
      context: .
    restart: unless-stopped
    env_file:
      - .env
    deploy:
      replicas: 2

  # Nginx proxy
  proxy:
    build:
      context: docker/nginx
    restart: unless-stopped
    env_file:
      - .env
    depends_on:
      - app
    ports:
      - 80:80
      - 443:443
    volumes:
      - certbot-web:/vol/www
      - proxy-dhparams:/vol/proxy
      - certbot-certs:/etc/letsencrypt
    environment:
      - DOMAIN=${DOMAIN}

  # Certbot for certificate
  certbot:
    build:
      context: ./docker/certbot
    command: echo "Skipping..."
    environment:
      - EMAIL=${ACME_DEFAULT_EMAIL}
      - DOMAIN=${DOMAIN}
    volumes:
      - certbot-web:/vol/www
      - certbot-certs:/etc/letsencrypt/
    depends_on:
      - proxy
    env_file:
      - .env

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
    container_name: elasticsearch
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:7.4.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch

  # Redis Cache
  # Acts as both cache and message broker for celery
  redis:
    restart: unless-stopped
    image: redis:7.0.5-alpine
    expose:
      - 6379
    env_file:
      - .env
  # Postgres Database
  db:
    image: postgres:14.0-alpine
    restart: unless-stopped
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      POSTGRES_DB: blogs_api
      POSTGRES_USER: django
      POSTGRES_PASSWORD: django
    expose:
      - 5432
    env_file:
      - .env

  # Celery beat scheduler, sends tasks to queue
  celery_beat:
    build:
      context: .
    command: "pipenv run celery -A blogs_api beat"
    depends_on:
      - db
      - redis
    env_file:
      - .env

  # Default celery consumer queue | Default, All tasks come to this consumer
  celery_default:
    build:
      context: .
    command: "pipenv run celery -A blogs_api worker -l info --concurrency 16 --pool threads -n default@%h"
    depends_on:
      - db
      - redis
    env_file:
      - .env

  # Flower to monitor celery
  flower:
    image: mher/flower
    command: 'celery flower --broker=${CELERY_BROKER_URL} flower --port=5555'
    expose:
      - 5555
    ports:
      - "5555:5555"
    depends_on:
      - db
      - redis


volumes:
  certbot-web:
  proxy-dhparams:
  certbot-certs: